{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8c6835-d676-4ced-b880-931fa2010831",
   "metadata": {},
   "source": [
    "## THIS IS FOR TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531313d-ad7e-47bb-a6c6-57209232d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 1: Cargar los Archivos CSV\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Definir las rutas a los directorios donde están los archivos CSV\n",
    "# Reemplaza estas rutas con las reales en tu sistema\n",
    "directory_2024 = 'path/to/2024/data'  # Ejemplo: 'data/2024'\n",
    "directory_2025 = 'path/to/2025/data'  # Ejemplo: 'data/2025'\n",
    "\n",
    "# Lista de nombres de archivos CSV (22 carreras por temporada)\n",
    "race_files_2024 = [f'race_{i}_2024.csv' for i in range(1, 23)]\n",
    "race_files_2025 = [f'race_{i}_2025.csv' for i in range(1, 23)]\n",
    "\n",
    "# Función para cargar los datos de una temporada\n",
    "def load_season_data(directory, race_files):\n",
    "    data = {}\n",
    "    for race in race_files:\n",
    "        file_path = os.path.join(directory, race)\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Verificar que todas las columnas esperadas estén presentes\n",
    "            expected_columns = ['Driver', 'DriverNumber', 'LapTime', 'LapNumber', 'Stint', \n",
    "                                'Sector1Time', 'Sector2Time', 'Sector3Time', 'Compound', \n",
    "                                'TyreLife', 'Team', 'Position']\n",
    "            if all(col in df.columns for col in expected_columns):\n",
    "                data[race] = df\n",
    "            else:\n",
    "                print(f\"Advertencia: El archivo {race} no tiene todas las columnas esperadas.\")\n",
    "        else:\n",
    "            print(f\"Archivo no encontrado: {file_path}\")\n",
    "    return data\n",
    "\n",
    "# Cargar datos de 2024 y 2025\n",
    "data_2024 = load_season_data(directory_2024, race_files_2024)\n",
    "data_2025 = load_season_data(directory_2025, race_files_2025)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 2: Procesar los Datos\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Función para calcular el tiempo de pole position (mejor tiempo de la primera vuelta)\n",
    "def calculate_pole_time(race_data):\n",
    "    first_lap_times = race_data[race_data['LapNumber'] == 1]['LapTime']\n",
    "    if not first_lap_times.empty:\n",
    "        return first_lap_times.min()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Función para calcular el tiempo promedio por vuelta para cada piloto en una carrera\n",
    "def calculate_avg_lap_time(race_data):\n",
    "    # Filtrar vueltas atípicas (ejemplo: excluir tiempos mayores a 2 veces el tiempo de pole)\n",
    "    pole_time = calculate_pole_time(race_data)\n",
    "    if np.isnan(pole_time):\n",
    "        return {}\n",
    "    filtered_data = race_data[race_data['LapTime'] < 2 * pole_time]\n",
    "    avg_lap_times = filtered_data.groupby('Driver')['LapTime'].mean().to_dict()\n",
    "    return avg_lap_times\n",
    "\n",
    "# Función para calcular el rendimiento normalizado p_{i,j} = tiempo_promedio / tiempo_pole\n",
    "def calculate_performance(data):\n",
    "    performance = {}\n",
    "    for race, race_data in data.items():\n",
    "        pole_time = calculate_pole_time(race_data)\n",
    "        if np.isnan(pole_time):\n",
    "            continue\n",
    "        avg_lap_times = calculate_avg_lap_time(race_data)\n",
    "        performance[race] = {driver: avg_time / pole_time for driver, avg_time in avg_lap_times.items()}\n",
    "    return performance\n",
    "\n",
    "# Calcular rendimiento para 2024 y 2025\n",
    "performance_2024 = calculate_performance(data_2024)\n",
    "performance_2025 = calculate_performance(data_2025)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 3: Crear Secuencias para el Modelo LSTM\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Función para crear secuencias de entrada\n",
    "def create_sequences(performance, race_files, target_race_index):\n",
    "    sequences = []\n",
    "    additional_features = []\n",
    "    targets = []\n",
    "    drivers = list(performance[race_files[0]].keys())  # Pilotos de la primera carrera\n",
    "\n",
    "    for driver in drivers:\n",
    "        sequence = []\n",
    "        for i in range(target_race_index):\n",
    "            race = race_files[i]\n",
    "            if race in performance and driver in performance[race]:\n",
    "                sequence.append(performance[race][driver])\n",
    "            else:\n",
    "                sequence.append(np.nan)\n",
    "        sequences.append(sequence)\n",
    "\n",
    "        # Característica adicional: rendimiento en la misma carrera de 2024\n",
    "        race_2024 = f'race_{target_race_index + 1}_2024.csv'\n",
    "        if race_2024 in performance_2024 and driver in performance_2024[race_2024]:\n",
    "            additional_features.append(performance_2024[race_2024][driver])\n",
    "        else:\n",
    "            additional_features.append(np.nan)\n",
    "\n",
    "        # Objetivo: rendimiento en la carrera objetivo\n",
    "        target_race = race_files[target_race_index]\n",
    "        if target_race in performance and driver in performance[target_race]:\n",
    "            targets.append(performance[target_race][driver])\n",
    "        else:\n",
    "            targets.append(np.nan)\n",
    "\n",
    "    # Eliminar pilotos con datos faltantes\n",
    "    valid_indices = [i for i in range(len(targets)) if not np.isnan(targets[i]) and not np.any(np.isnan(sequences[i])) and not np.isnan(additional_features[i])]\n",
    "    sequences = [sequences[i] for i in valid_indices]\n",
    "    additional_features = [additional_features[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "\n",
    "    return np.array(sequences), np.array(additional_features), np.array(targets), [drivers[i] for i in valid_indices]\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 4: Diseñar el Modelo LSTM\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Parámetros ajustables de la red LSTM\n",
    "lstm_units = 64          # Número de unidades en la capa LSTM\n",
    "dense_units = 32         # Número de unidades en la capa densa adicional (opcional)\n",
    "dropout_rate = 0.2       # Tasa de dropout para regularización\n",
    "epochs = 50              # Número de épocas de entrenamiento\n",
    "batch_size = 32          # Tamaño del batch\n",
    "learning_rate = 0.001    # Tasa de aprendizaje\n",
    "\n",
    "# Definir las entradas del modelo\n",
    "sequence_input = Input(shape=(None, 1), name='sequence_input')      # Secuencia de rendimientos previos\n",
    "additional_input = Input(shape=(1,), name='additional_input')       # Rendimiento en la misma carrera de 2024\n",
    "\n",
    "# Capa LSTM para procesar la secuencia temporal\n",
    "lstm_out = LSTM(lstm_units)(sequence_input)\n",
    "\n",
    "# Agregar dropout para regularización\n",
    "lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "\n",
    "# Concatenar la salida de la LSTM con la característica adicional\n",
    "concat = Concatenate()([lstm_out, additional_input])\n",
    "\n",
    "# Capa densa adicional (opcional)\n",
    "dense_out = Dense(dense_units, activation='relu')(concat)\n",
    "dense_out = Dropout(dropout_rate)(dense_out)\n",
    "\n",
    "# Capa de salida para predecir el rendimiento\n",
    "output = Dense(1, activation='linear')(dense_out)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Model(inputs=[sequence_input, additional_input], outputs=output)\n",
    "\n",
    "# Compilar el modelo con optimizador Adam y pérdida de error cuadrático medio\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
    "\n",
    "# Mostrar un resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 5: Entrenamiento del Modelo\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Crear datos de entrenamiento usando las carreras de 2024\n",
    "def create_training_data(performance, race_files):\n",
    "    X_seq_list = []\n",
    "    X_add_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for k in range(1, len(race_files)):\n",
    "        sequences, additional_features, targets, _ = create_sequences(performance, race_files, k)\n",
    "        if len(sequences) > 0:\n",
    "            X_seq_list.append(sequences)\n",
    "            X_add_list.append(additional_features)\n",
    "            y_list.append(targets)\n",
    "\n",
    "    if len(X_seq_list) == 0:\n",
    "        return np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    X_seq_train = np.concatenate(X_seq_list, axis=0)\n",
    "    X_add_train = np.concatenate(X_add_list, axis=0)\n",
    "    y_train = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    return X_seq_train, X_add_train, y_train\n",
    "\n",
    "# Generar datos de entrenamiento con datos de 2024\n",
    "X_seq_train, X_add_train, y_train = create_training_data(performance_2024, race_files_2024)\n",
    "\n",
    "# Ajustar las dimensiones para la entrada de la LSTM\n",
    "X_seq_train = X_seq_train.reshape(X_seq_train.shape[0], X_seq_train.shape[1], 1)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit([X_seq_train, X_add_train], y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Visualizar la pérdida durante el entrenamiento\n",
    "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
    "plt.title('Pérdida del Modelo Durante el Entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 6: Predicción para una Carrera de 2025\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Función para predecir el rendimiento en la carrera k de 2025\n",
    "def predict_race_k(model, performance_2025, performance_2024, k):\n",
    "    sequences, additional_features, _, drivers = create_sequences(performance_2025, race_files_2025, k-1)\n",
    "    if len(sequences) == 0:\n",
    "        print(\"No hay datos suficientes para hacer predicciones.\")\n",
    "        return []\n",
    "    sequences = sequences.reshape(sequences.shape[0], sequences.shape[1], 1)\n",
    "    predictions = model.predict([sequences, additional_features], verbose=0)\n",
    "    return list(zip(drivers, predictions.flatten()))\n",
    "\n",
    "# Ejemplo: predecir la carrera 5 de 2025\n",
    "k = 5\n",
    "predictions = predict_race_k(model, performance_2025, performance_2024, k)\n",
    "\n",
    "if predictions:\n",
    "    # Ordenar pilotos según el rendimiento predicho (menor p_{i,j} = mejor)\n",
    "    sorted_drivers = sorted(predictions, key=lambda x: x[1])\n",
    "    podium = [driver for driver, _ in sorted_drivers[:3]]\n",
    "\n",
    "    # Mostrar el podio predicho\n",
    "    print(f\"\\nPredicción del podio para la carrera {k} de 2025:\")\n",
    "    for i, driver in enumerate(podium, 1):\n",
    "        print(f\"Posición {i}: {driver}\")\n",
    "else:\n",
    "    print(\"No se pudieron hacer predicciones para la carrera seleccionada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601964dd-7cef-47cd-8808-6801fbf36c62",
   "metadata": {},
   "source": [
    "#### 1. Incluir Más Características en la Secuencia\n",
    "#### Idea: Usa más variables como entradas para las secuencias.\n",
    "\n",
    "#### Características:\n",
    "#### Tiempos por sector (Sector1Time, Sector2Time, Sector3Time).\n",
    "\n",
    "#### Compuesto de neumáticos (Compound, codificado como numérico: Soft=1, Medium=2, Hard=3).\n",
    "\n",
    "#### Vida útil del neumático (TyreLife).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb25b46-aa49-460d-91a0-95ab2258f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(race_data):\n",
    "    pole_time = calculate_pole_time(race_data)\n",
    "    features = race_data.groupby('Driver').agg({\n",
    "        'LapTime': 'mean',\n",
    "        'Sector1Time': 'mean',\n",
    "        'Sector2Time': 'mean',\n",
    "        'Sector3Time': 'mean',\n",
    "        'TyreLife': 'mean',\n",
    "        'Compound': lambda x: pd.Series(x).mode()[0]  # Compuesto más usado\n",
    "    }).to_dict('index')\n",
    "    for driver in features:\n",
    "        features[driver]['LapTime'] /= pole_time\n",
    "        features[driver]['Sector1Time'] /= pole_time\n",
    "        features[driver]['Sector2Time'] /= pole_time\n",
    "        features[driver]['Sector3Time'] /= pole_time\n",
    "        # Codificar Compound\n",
    "        compound_mapping = {'Soft': 1, 'Medium': 2, 'Hard': 3}\n",
    "        features[driver]['Compound'] = compound_mapping.get(features[driver]['Compound'], 0)\n",
    "    return features\n",
    "\n",
    "#sequence_input = Input(shape=(None, 6), name='sequence_input')  # 6 características por paso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ffb35-df8a-476b-af98-1ffd25b22dcd",
   "metadata": {},
   "source": [
    "#### Idea: Calcula estadísticas por carrera como entradas adicionales.\n",
    "\n",
    "#### Ejemplos:\n",
    "#### Desviación estándar de LapTime (consistencia).\n",
    "\n",
    "#### Número de stints (Stint único).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b583293b-942b-48ef-8887-bd37a550f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_input = Input(shape=(3,), name='additional_input')  # Ejemplo: 3 características agregadas\n",
    "#dense_out = Dense(64, activation='relu')(dense_out)\n",
    "#dense_out = Dropout(dropout_rate)(dense_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36d3cd-8a69-4a46-aa35-ea1eae1a04c2",
   "metadata": {},
   "source": [
    "=========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961f14f-3aa4-4151-891c-af907b952775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3aaabc-9f93-4db3-8d1e-deabb920cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla para reproducibilidad\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de95acd-e9c4-4799-8b8f-3f899ef43d24",
   "metadata": {},
   "source": [
    "# ----------------------------------------------\n",
    "# Paso 1: Cargar los Datos\n",
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a7682-df38-4c7a-8c81-c3f3fb864124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al directorio con los datos (ajusta según tu sistema)\n",
    "directory = 'path/to/2024/data'\n",
    "race_files = [f'race_{i}_2024.csv' for i in range(1, 23)]  # 22 carreras\n",
    "\n",
    "def load_data(directory, race_files):\n",
    "    data = {}\n",
    "    for race in race_files:\n",
    "        file_path = os.path.join(directory, race)\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            data[race] = df\n",
    "        else:\n",
    "            print(f\"Archivo no encontrado: {file_path}\")\n",
    "    return data\n",
    "\n",
    "data = load_data(directory, race_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a344e5-e9bc-4e5b-bba5-d4c5961acbce",
   "metadata": {},
   "source": [
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 2: Procesar los Datos\n",
    "# ----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28495dd3-253a-4703-bbe0-ee9ac1e3d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_pole_time(race_data):\n",
    "    first_lap_times = race_data[race_data['LapNumber'] == 1]['LapTime']\n",
    "    return first_lap_times.min() if not first_lap_times.empty else np.nan\n",
    "\n",
    "def calculate_avg_lap_time(race_data):\n",
    "    pole_time = calculate_pole_time(race_data)\n",
    "    if np.isnan(pole_time):\n",
    "        return {}\n",
    "    filtered_data = race_data[race_data['LapTime'] < 2 * pole_time]\n",
    "    return filtered_data.groupby('Driver')['LapTime'].mean().to_dict()\n",
    "\n",
    "def calculate_performance(data):\n",
    "    performance = {}\n",
    "    for race, race_data in data.items():\n",
    "        pole_time = calculate_pole_time(race_data)\n",
    "        if np.isnan(pole_time):\n",
    "            continue\n",
    "        avg_lap_times = calculate_avg_lap_time(race_data)\n",
    "        performance[race] = {driver: avg_time / pole_time for driver, avg_time in avg_lap_times.items()}\n",
    "    return performance\n",
    "\n",
    "performance = calculate_performance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2bea06-7f46-4ea3-9222-55afeb328dfa",
   "metadata": {},
   "source": [
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 3: Dividir en Entrenamiento, Validación y Prueba\n",
    "# ----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bee532-b71a-426c-9eed-e1be311cd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_races = race_files[:15]  # Carreras 1-15\n",
    "val_races = race_files[15:18]  # Carreras 16-18\n",
    "test_races = race_files[18:]   # Carreras 19-22\n",
    "\n",
    "def create_sequences(performance, race_files, target_race_index):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    drivers = list(performance[race_files[0]].keys())\n",
    "    \n",
    "    for driver in drivers:\n",
    "        sequence = []\n",
    "        for i in range(target_race_index):\n",
    "            race = race_files[i]\n",
    "            sequence.append(performance.get(race, {}).get(driver, np.nan))\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "        target_race = race_files[target_race_index]\n",
    "        targets.append(performance.get(target_race, {}).get(driver, np.nan))\n",
    "    \n",
    "    valid_indices = [i for i in range(len(targets)) if not np.isnan(targets[i]) and not np.any(np.isnan(sequences[i]))]\n",
    "    sequences = [sequences[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "    drivers = [drivers[i] for i in valid_indices]\n",
    "    \n",
    "    return np.array(sequences), np.array(targets), drivers\n",
    "\n",
    "# Datos de entrenamiento\n",
    "X_train, y_train, drivers_train = create_sequences(performance, train_races, len(train_races) - 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "# Datos de validación\n",
    "X_val, y_val, drivers_val = create_sequences(performance, val_races, len(val_races) - 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "\n",
    "# Datos de prueba\n",
    "X_test, y_test, drivers_test = create_sequences(performance, test_races, len(test_races) - 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c7f8e-93b8-4285-8bcc-3ef3257e7cd6",
   "metadata": {},
   "source": [
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 4: Diseñar y Entrenar el Modelo LSTM\n",
    "# ----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75bbda-18c1-4ef6-bd2f-6166214e2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(None, 1))\n",
    "lstm_out = LSTM(64)(sequence_input)\n",
    "lstm_out = Dropout(0.2)(lstm_out)\n",
    "output = Dense(1, activation='linear')(lstm_out)\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Entrenar con validación\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                    epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Graficar pérdida\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida Durante el Entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb729a9-f592-4823-8cb4-803f06af5d61",
   "metadata": {},
   "source": [
    "\n",
    "# ----------------------------------------------\n",
    "# Paso 5: Predicción y Evaluación en Prueba\n",
    "# ----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1faf12-d871-4b51-add7-7f9000a7bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Calcular métricas\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "spearman_corr, _ = spearmanr(y_test, predictions)\n",
    "top3_true = np.argsort(y_test)[:3]\n",
    "top3_pred = np.argsort(predictions.flatten())[:3]\n",
    "accuracy_top3 = len(set(top3_true) & set(top3_pred)) / 3\n",
    "\n",
    "print(\"\\nMétricas de evaluación:\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"Correlación de Spearman: {spearman_corr:.4f}\")\n",
    "print(f\"Precisión top-3: {accuracy_top3:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09bd71-cc33-410b-935b-dc23bed3c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar predicciones para la próxima carrera (ejemplo: carrera 19)\n",
    "print(f\"\\nPredicciones para la carrera {test_races[0]}:\")\n",
    "sorted_predictions = sorted(zip(drivers_test, predictions.flatten()), key=lambda x: x[1])\n",
    "for i, (driver, pred) in enumerate(sorted_predictions[:3], 1):\n",
    "    print(f\"Posición {i}: {driver}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python neuralEnv",
   "language": "python",
   "name": "neuralenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
